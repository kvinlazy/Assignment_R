---
title: "Prediction Assignment"
author: "Kevin Naik"
date: "`r Sys.Date()`"
output:
  prettydoc::html_pretty:
    theme: leonids
    highlight: github
vignette: >
  %\VignetteIndexEntry{Vignette Title}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include=FALSE}
knitr::opts_chunk$set(echo=FALSE, warning=FALSE)
```


### Import Library

```{r echo=TRUE, results='hide'}
library(caret)
library(dplyr)
library(rattle)
library(randomForest)
```

### Download data CSV files
##### Dataset: [Train dataset](https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv)
##### Dataset: [Test dataset](https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv)
```{r echo = TRUE}

download.file('https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv',"training.csv", quiet=FALSE)
download.file('https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv',"testing.csv", quiet=FALSE)
```
### Read Data in CSV

```{r echo = TRUE}
train_data<- read.csv("training.csv")
test_data<- read.csv("testing.csv")
```
### Cleaning the data
#### Observing the data cleaning is required.
#### Step1 remove NA, "", #DIV/0!.
#### Step2 remove Variables near to zero and NA.
#### Step3 remove Non-numerical variable like timestamp.

```{r echo = TRUE}
train_data <- read.csv('training.csv', na.strings = c("NA", "#DIV/0!", ""))
test_data <-  read.csv('testing.csv', na.strings = c("NA", "#DIV/0!", ""))
nz <- nearZeroVar(train_data)
train_data <- train_data[,-nz]
test_data <- test_data[,-nz]
rm_na <- sapply(train_data, function(x) mean(is.na(x))) > 0.95
train_data <- train_data[,rm_na == FALSE]
test_data <- test_data[,rm_na == FALSE]
train_data<- train_data[, -c(1:7)]
test_data<- test_data[, -c(1:7)]
```
### Split the Training Dataset
```{r echo = TRUE,results = FALSE}
inTrainIndex <- createDataPartition(train_data$classe, p=0.6)[[1]]
train_data <- train_data[inTrainIndex,]
testcv_data <- train_data[-inTrainIndex,]
```
### Machine Learning Algorithm for Prediction 
* Decision Tree
* Random Forest

```{r echo = TRUE}
dt_model <- train(classe ~., method='rpart', data=train_data)
dt_Prediction <- predict(dt_model, testcv_data)
confusionMatrix(testcv_data$classe, dt_Prediction)
```

```{r echo = TRUE}
rf_model <- train(classe ~., method='rf', data=train_data, ntree=10)
rf_prediction <- predict(rf_model, testcv_data)
confusionMatrix(testcv_data$classe, rf_prediction)
```

### Result
* From the confusion matrix it is clear that random forest algorithm works better than decision tree. So using random forest model the prediction should be made.

### Conclusion 
```{r echo = TRUE}
predict(rf_model, test_data)
```
